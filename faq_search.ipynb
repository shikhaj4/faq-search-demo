# ------------------------------
# FAQ Search with Embeddings + FAISS + Reranking
# ------------------------------
# !pip install -q datasets sentence-transformers faiss-cpu torch

import json
import numpy as np
from datasets import load_dataset
from sentence_transformers import SentenceTransformer, CrossEncoder, util
import faiss

# ------------------------------
# CONFIG
# ------------------------------
DATASET_NAME = "rjac/e-commerce-customer-support-qa"
EMBED_MODEL = "all-MiniLM-L6-v2"
RERANK_MODEL = "cross-encoder/ms-marco-MiniLM-L-6-v2"
TOP_K = 4
NPROBE = 10

# ------------------------------
# 1) Load dataset and extract Q/A
# ------------------------------
print("Loading dataset:", DATASET_NAME)
ds = load_dataset(DATASET_NAME)["train"]

questions, answers = [], []
for item in ds:
    try:
        qa_json = json.loads(item["qa"])
        for entry in qa_json.get("knowledge", []):
            q = entry.get("customer_summary_question") or entry.get("question")
            a = entry.get("agent_summary_solution") or entry.get("answer")
            if q and a:
                questions.append(q.strip())
                answers.append(a.strip())
    except Exception:
        pass

print("Extracted pairs:", len(questions))

# ------------------------------
# 2) Encode questions
# ------------------------------
embed_model = SentenceTransformer(EMBED_MODEL)
embeddings = embed_model.encode(questions, convert_to_numpy=True, show_progress_bar=True).astype("float32")
faiss.normalize_L2(embeddings)

# ------------------------------
# 3) Build FAISS index
# ------------------------------
d = embeddings.shape[1]
index = faiss.IndexIVFFlat(faiss.IndexFlatIP(d), d, 100, faiss.METRIC_INNER_PRODUCT)
index.train(embeddings)
index.add(embeddings)
index.nprobe = NPROBE
print("Index built with", index.ntotal, "items.")

# ------------------------------
# 4) Load reranker
# ------------------------------
try:
    reranker = CrossEncoder(RERANK_MODEL)
except:
    reranker = None
    print("Cross-encoder not available, fallback to embedding similarity.")

# ------------------------------
# 5) Search function
# ------------------------------
def search(query, top_k=TOP_K):
    q_emb = embed_model.encode([query], convert_to_numpy=True).astype("float32")
    faiss.normalize_L2(q_emb)
    D, I = index.search(q_emb, top_k*5)
    candidates = [(questions[i], answers[i], D[0][j]) for j,i in enumerate(I[0]) if i != -1]

    if reranker:
        pairs = [(query, q) for q, _, _ in candidates]
        scores = reranker.predict(pairs)
        ranked = sorted(zip(candidates, scores), key=lambda x: x[1], reverse=True)
    else:
        ranked = sorted(candidates, key=lambda x: x[2], reverse=True)

    return ranked[:top_k]

# ------------------------------
# 6) Example queries
# ------------------------------
queries = [
    "I can't log into my account because of email verification",
    "How do I return a product I purchased?",
    "My delivery is delayed, where is my order?"
]

for q in queries:
    print("\nQuery:", q)
    for rank, res in enumerate(search(q), 1):
        if reranker:
            (ques, ans, _), score = res
        else:
            ques, ans, score = res
        print(f"Rank {rank} | Score={score:.4f}")
        print("Q:", ques)
        print("A:", ans[:200], "...\n")
